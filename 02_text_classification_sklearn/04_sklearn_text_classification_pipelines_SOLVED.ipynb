{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "POe5i2WQC8GA",
    "outputId": "988f53c6-cd3e-4e80-9ee4-c14458444825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn version: 0.20.3\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "print('Sklearn version:', sklearn_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oE8GAfvC8GF"
   },
   "source": [
    "# The data\n",
    "\n",
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TD3mk9l_C8GG"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                 remove=('headers', 'footers', 'quotes'),\n",
    "                 categories=categories, shuffle=True, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zq70BkgSC8GI"
   },
   "source": [
    "## Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "6YOFxIh5C8GJ",
    "outputId": "67163803-f9b0-4d87-8d4f-6c1e8a452f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=5000, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "       ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "# Fit all the pipeline\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "K6jV6XuxC8GM",
    "outputId": "00deb573-7fc7-4d65-f3c4-ea8be1f40616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7989347536617842\n"
     ]
    }
   ],
   "source": [
    "#Evaluate test data\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                    remove=('headers', 'footers', 'quotes'),\n",
    "                    categories=categories, \n",
    "                    shuffle=True, random_state=42)\n",
    "\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vI02Sv9_C8GP"
   },
   "source": [
    "## Change classifier in the pipeline\n",
    "    - LinearSVC\n",
    "    - k-NN\n",
    "    - Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hZdWz-9vC8GQ",
    "outputId": "bb77920e-8d52-40b3-af6a-fd417a0b0477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8089214380825566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC()),\n",
    "                    ])\n",
    "\n",
    "#Fit\n",
    "_ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# Predict\n",
    "predicted = text_clf_svm.predict(twenty_test.data)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LjlliVD2C8GT",
    "outputId": "b7ff4390-a02c-4455-fd56-3aa2ff68a978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.25233022636484687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=20)),\n",
    "                    ])\n",
    "\n",
    "_ = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vdiDV6ItC8GY",
    "outputId": "d9fa4fb6-731d-4f3c-b37e-f1c4fe6d84a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7476697736351531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                    ])\n",
    "\n",
    "_ = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jF-HctlC8Ga"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yTbs_rVC8Gc"
   },
   "source": [
    "## Use features from a factorization instead the provided by the tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4KNonaAuC8Gd",
    "outputId": "c291c431-48b9-4c85-e42e-e230187edbe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing, tokenizing and filtering of stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=5000,\n",
    "                                stop_words='english')\n",
    "X_train_counts = tf_vectorizer.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4GjVYsQpC8Gg",
    "outputId": "9a41736c-3bf6-4692-f537-3681875d61d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 794 µs, total: 3.37 s\n",
      "Wall time: 3.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import  LatentDirichletAllocation\n",
    "\n",
    "n_components = 6\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_components,\n",
    "                                max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7o_H0X_KC8Gi",
    "outputId": "3a80802e-de32-43bb-c997-7ac144841e04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.transform(X_train_counts).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "colab_type": "code",
    "id": "cS9qSPb8C8Gl",
    "outputId": "102af2bf-15af-4a14-d20e-748ef4a4dbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "church pope catholic marriage authority married orthodox canon schism mass liturgy bishop ceremony st churches catholics does priest jurisdiction coptic\n",
      "Topic #1:\n",
      "image file jpeg use program files images gif color know format does thanks graphics software using version bit available like\n",
      "Topic #2:\n",
      "edu com graphics mail send pub keyboard ftp data computer information cs systems software ca faq available gov contact pc\n",
      "Topic #3:\n",
      "god people think don jesus just does believe know say like time bible way things good true life christian question\n",
      "Topic #4:\n",
      "health use medical years people disease food msg new patients like don doctor research time 1993 10 day know just\n",
      "Topic #5:\n",
      "banks gordon skepticism edu soon pitt geb intellect chastity n3jxp dsl shameful cadre surrender father spirit son holy int col\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "n_top_words = 20\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lKg7d9ZC8Go"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYZoQYRZC8Gr"
   },
   "source": [
    "## Pipeline with factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "U1ym3haYC8Gs",
    "outputId": "d4f2ecb0-a139-4e3c-d310-3302d4730304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7003994673768309\n",
      "CPU times: user 1min 30s, sys: 48.4 s, total: 2min 18s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "text_lda_knn = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=10000, stop_words='english')),\n",
    "                         ('lda', LatentDirichletAllocation(n_components=150, max_iter=15,\n",
    "                                 learning_method='online',\n",
    "                                 learning_offset=200.,\n",
    "                                 random_state=0)),\n",
    "                         ('clf', KNeighborsClassifier(n_neighbors=10))\n",
    "                        ])\n",
    "\n",
    "                         \n",
    "_ = text_lda_knn.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_lda_knn.predict(twenty_test.data)\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "0txB9bLyC8Gv",
    "outputId": "ee1351e5-b307-43f8-e793-01157836faef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6864181091877497\n",
      "CPU times: user 1min 32s, sys: 48.5 s, total: 2min 20s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_lda_rf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=10000, stop_words='english')),\n",
    "                         ('lda', LatentDirichletAllocation(n_components=150, max_iter=15,\n",
    "                                 learning_method='online',\n",
    "                                 learning_offset=200.,\n",
    "                                 random_state=0)),\n",
    "                         ('clf', RandomForestClassifier(n_estimators=100)),\n",
    "                        ])\n",
    "\n",
    "                         \n",
    "_ = text_lda_rf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "predicted = text_lda_rf.predict(twenty_test.data)\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlBpfFFVC8Gy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHsx24QAC8G1"
   },
   "source": [
    "## Optimize a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "WB-G6qwuC8G1",
    "outputId": "c5194c17-d97f-4ac5-febf-2dcd61baa8a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "CPU times: user 19.1 s, sys: 53.1 ms, total: 19.1 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define estimator. No parameters of the search\n",
    "clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LinearSVC()),\n",
    "                ])\n",
    "\n",
    "# Specify parameters and distributions to sample from\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_dist = {\"vect__max_features\": [1000, 2500, 5000, 7500, 10000, None], \n",
    "              \"vect__stop_words\": ['english', None], \n",
    "              \"clf__C\": [.1, .5, 1., 1.5, 2.]}\n",
    "\n",
    "# Define randomized search\n",
    "n_iter_search = 10\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search, return_train_score=True)\n",
    "\n",
    "# Run the randomized search\n",
    "random_search.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "A692BUDAC8G5",
    "outputId": "f7e74aba-ab46-4c2d-e626-ba4f2b4dd061"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vect__stop_words</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.337459</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.110284</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>None</td>\n",
       "      <td>2500</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vect__stop_words': None, 'vect__max_features...</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.823373</td>\n",
       "      <td>0.824234</td>\n",
       "      <td>0.825432</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>7</td>\n",
       "      <td>0.981383</td>\n",
       "      <td>0.983378</td>\n",
       "      <td>0.980744</td>\n",
       "      <td>0.981835</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.273749</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.096364</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>english</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.841965</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.832224</td>\n",
       "      <td>0.834293</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.980718</td>\n",
       "      <td>0.976760</td>\n",
       "      <td>0.978734</td>\n",
       "      <td>0.001616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.319346</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.103301</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>english</td>\n",
       "      <td>None</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.876494</td>\n",
       "      <td>0.853918</td>\n",
       "      <td>0.868176</td>\n",
       "      <td>0.866194</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.982072</td>\n",
       "      <td>0.983386</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305115</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.109710</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>None</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'vect__stop_words': None, 'vect__max_features...</td>\n",
       "      <td>0.833997</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.813582</td>\n",
       "      <td>0.816128</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>9</td>\n",
       "      <td>0.932846</td>\n",
       "      <td>0.931516</td>\n",
       "      <td>0.934263</td>\n",
       "      <td>0.932875</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333399</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.102019</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>english</td>\n",
       "      <td>7500</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.871182</td>\n",
       "      <td>0.852590</td>\n",
       "      <td>0.858855</td>\n",
       "      <td>0.860877</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.982072</td>\n",
       "      <td>0.983386</td>\n",
       "      <td>0.000929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.309382</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.105013</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>english</td>\n",
       "      <td>7500</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.879150</td>\n",
       "      <td>0.855246</td>\n",
       "      <td>0.865513</td>\n",
       "      <td>0.866637</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983378</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.982943</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.339095</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.105586</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>english</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.873838</td>\n",
       "      <td>0.852590</td>\n",
       "      <td>0.868176</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.008988</td>\n",
       "      <td>3</td>\n",
       "      <td>0.984707</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.982072</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.267068</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.094573</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>english</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.818061</td>\n",
       "      <td>0.806109</td>\n",
       "      <td>0.802929</td>\n",
       "      <td>0.809039</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>10</td>\n",
       "      <td>0.916888</td>\n",
       "      <td>0.919548</td>\n",
       "      <td>0.916999</td>\n",
       "      <td>0.917812</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.315408</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.115294</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>None</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'vect__stop_words': None, 'vect__max_features...</td>\n",
       "      <td>0.843293</td>\n",
       "      <td>0.818061</td>\n",
       "      <td>0.825566</td>\n",
       "      <td>0.828977</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>6</td>\n",
       "      <td>0.954122</td>\n",
       "      <td>0.950798</td>\n",
       "      <td>0.947543</td>\n",
       "      <td>0.950821</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.295355</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.096506</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>english</td>\n",
       "      <td>2500</td>\n",
       "      <td>1.5</td>\n",
       "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
       "      <td>0.827357</td>\n",
       "      <td>0.815405</td>\n",
       "      <td>0.822903</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>8</td>\n",
       "      <td>0.982713</td>\n",
       "      <td>0.982713</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.982278</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.337459      0.003923         0.110284        0.006579   \n",
       "1       0.273749      0.005288         0.096364        0.006197   \n",
       "2       0.319346      0.006841         0.103301        0.005527   \n",
       "3       0.305115      0.005771         0.109710        0.006599   \n",
       "4       0.333399      0.004365         0.102019        0.005683   \n",
       "5       0.309382      0.007715         0.105013        0.008684   \n",
       "6       0.339095      0.003503         0.105586        0.003889   \n",
       "7       0.267068      0.002429         0.094573        0.006572   \n",
       "8       0.315408      0.005662         0.115294        0.007816   \n",
       "9       0.295355      0.005530         0.096506        0.004703   \n",
       "\n",
       "  param_vect__stop_words param_vect__max_features param_clf__C  \\\n",
       "0                   None                     2500            1   \n",
       "1                english                     2500          0.5   \n",
       "2                english                     None          1.5   \n",
       "3                   None                     2500          0.1   \n",
       "4                english                     7500            2   \n",
       "5                english                     7500            1   \n",
       "6                english                    10000            2   \n",
       "7                english                     1000          0.1   \n",
       "8                   None                    10000          0.1   \n",
       "9                english                     2500          1.5   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'vect__stop_words': None, 'vect__max_features...           0.828685   \n",
       "1  {'vect__stop_words': 'english', 'vect__max_fea...           0.841965   \n",
       "2  {'vect__stop_words': 'english', 'vect__max_fea...           0.876494   \n",
       "3  {'vect__stop_words': None, 'vect__max_features...           0.833997   \n",
       "4  {'vect__stop_words': 'english', 'vect__max_fea...           0.871182   \n",
       "5  {'vect__stop_words': 'english', 'vect__max_fea...           0.879150   \n",
       "6  {'vect__stop_words': 'english', 'vect__max_fea...           0.873838   \n",
       "7  {'vect__stop_words': 'english', 'vect__max_fea...           0.818061   \n",
       "8  {'vect__stop_words': None, 'vect__max_features...           0.843293   \n",
       "9  {'vect__stop_words': 'english', 'vect__max_fea...           0.827357   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.823373           0.824234         0.825432        0.002329   \n",
       "1           0.828685           0.832224         0.834293        0.005617   \n",
       "2           0.853918           0.868176         0.866194        0.009326   \n",
       "3           0.800797           0.813582         0.816128        0.013679   \n",
       "4           0.852590           0.858855         0.860877        0.007727   \n",
       "5           0.855246           0.865513         0.866637        0.009795   \n",
       "6           0.852590           0.868176         0.864865        0.008988   \n",
       "7           0.806109           0.802929         0.809039        0.006515   \n",
       "8           0.818061           0.825566         0.828977        0.010583   \n",
       "9           0.815405           0.822903         0.821887        0.004934   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                7            0.981383            0.983378   \n",
       "1                5            0.978723            0.980718   \n",
       "2                2            0.984043            0.984043   \n",
       "3                9            0.932846            0.931516   \n",
       "4                4            0.984043            0.984043   \n",
       "5                1            0.983378            0.984043   \n",
       "6                3            0.984707            0.984043   \n",
       "7               10            0.916888            0.919548   \n",
       "8                6            0.954122            0.950798   \n",
       "9                8            0.982713            0.982713   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.980744          0.981835         0.001122  \n",
       "1            0.976760          0.978734         0.001616  \n",
       "2            0.982072          0.983386         0.000929  \n",
       "3            0.934263          0.932875         0.001122  \n",
       "4            0.982072          0.983386         0.000929  \n",
       "5            0.981408          0.982943         0.001119  \n",
       "6            0.982072          0.983607         0.001119  \n",
       "7            0.916999          0.917812         0.001229  \n",
       "8            0.947543          0.950821         0.002686  \n",
       "9            0.981408          0.982278         0.000615  "
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dictionary of search results to a Pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df_cv_results = pd.DataFrame.from_dict(random_search.cv_results_)\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "S3kuqDe8C8G8",
    "outputId": "7c1046e3-0976-44c7-edb3-aa70583adfca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'vect__stop_words': 'english', 'vect__max_features': 7500, 'clf__C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('Best params:', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OOjUQE4GC8HA",
    "outputId": "6f3bce15-7e7f-4428-a314-5288e0e722ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8202396804260985\n"
     ]
    }
   ],
   "source": [
    "# Score & evaluate test data using the best estimator\n",
    "\n",
    "predicted = random_search.best_estimator_.predict(twenty_test.data)\n",
    "\n",
    "print('Test accuracy:', np.mean(predicted == twenty_test.target))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xr5dyXhhC8HD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkKYi4qvC8HE"
   },
   "source": [
    "## Aditional metrics for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "T-f1v5_NC8HF",
    "outputId": "0e17f13c-80b9-4b52-ac7b-0484a5655f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.77      0.63      0.69       319\n",
      "         comp.graphics       0.82      0.92      0.87       389\n",
      "               sci.med       0.88      0.85      0.87       396\n",
      "soc.religion.christian       0.80      0.84      0.82       398\n",
      "\n",
      "             micro avg       0.82      0.82      0.82      1502\n",
      "             macro avg       0.82      0.81      0.81      1502\n",
      "          weighted avg       0.82      0.82      0.82      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, \n",
    "                                    predicted,\n",
    "                                    target_names=twenty_test.target_names))\n",
    "\n",
    "# Precision is the ratio tp / (tp + fp)\n",
    "# Recall is the ratio tp / (tp + fn)\n",
    "# The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, \n",
    "  # where an F-beta score reaches its best value at 1 and worst score at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "RApjmR4WC8HH",
    "outputId": "0b8cc99b-796b-4520-a169-81fad292f830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200,  22,  24,  73],\n",
       "       [ 15, 359,  15,   0],\n",
       "       [ 14,  32, 337,  13],\n",
       "       [ 32,  23,   7, 336]])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeR4njW3C8HN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_sklearn_text_classification_pipelines_SOLVED.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
